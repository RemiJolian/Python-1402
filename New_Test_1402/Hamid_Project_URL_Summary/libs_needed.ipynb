{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For create Summarize-URL-Text-To-Speech dash app, some librarys are needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These libs are needed:\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import IPython.display as ipd\n",
    "from IPython.display import display\n",
    "from gtts import gTTS\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "import base64\n",
    "import dash\n",
    "import requests\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bs4 \n",
    "is a Python library that works with your favorite parser to provide idiomatic ways of navigating,\n",
    "searching, and modifying the parse tree of HTML and XML files.\n",
    "It is a successor to the original Beautiful Soup library and offers more features, such as error-tolerant\n",
    "parsing and support for HTML5.\n",
    "The official name of PyPI's Beautiful Soup Python package is beautifulsoup4. \n",
    "# The BeautifulSoup module:\n",
    "it is a part of the bs4 library, which provides a high-level API for navigating,\n",
    "searching, and modifying the parse tree of HTML and XML files.\n",
    "It allows you to pull data out of HTML and XML files, navigate the parse tree, search for specific elements, \n",
    "and modify the content as needed.\n",
    "Beautiful Soup is often used for web scraping and other tasks that involve processing HTML or XML content.\n",
    "\n",
    "To use the BeautifulSoup module in Python, you can import it from the bs4 library as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, this lib is for scrapping of data from files like as HTML files\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can create a BeautifulSoup object with the HTML or XML content and use various methods to navigate, search, and modify the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<body>Some content</body>]\n"
     ]
    }
   ],
   "source": [
    "html_content = \"<html><body>Some content</body></html>\"\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "# find_all is a method of BeautifulSoap lib\n",
    "#find_all(tag_name, attrs=None, recursive=True, text=None, limit=None, errors=None)\n",
    "tags = soup.find_all('body')\n",
    "#title_soup = soup.title\n",
    "print(tags)\n",
    "#print(title_soup) : returns the title of the web\n",
    "#Also see:\n",
    "#response = requests.get(url)\n",
    "#soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, the 'html.parser' is used to parse the html_content and \n",
    "create a parse tree, which can then be used to navigate and manipulate the HTML content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will output:\n",
    "<body>Some content</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a popular choice for web scraping and other tasks that involve processing HTML or XML content due to its ease of use and powerful feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also read these content:\n",
    "# The line soup = BeautifulSoup(response.text, 'html.parser') creates a\n",
    "BeautifulSoup object that represents the parse tree of the HTML content obtained from the server.\n",
    "Here's how it works:\n",
    "response.text: This is the HTML content of the web page that you fetched using the requests.get() method. The text attribute returns the HTML content as a string.\n",
    "'html.parser': This is the name of the HTML parser that BeautifulSoup will use to parse the HTML content. By default, BeautifulSoup uses the html.parser from the html5lib library, which is a modern and forgiving HTML parser. However, you can also use other parsers like lxml or html5lib if needed.\n",
    "\n",
    "BeautifulSoup(response.text, 'html.parser'): This creates a BeautifulSoup object with the HTML content and the specified parser. The BeautifulSoup object represents the parse tree of the HTML content, which can be navigated, searched, and modified as needed.\n",
    "soup: This is the BeautifulSoup object that represents the parse tree of the HTML content. You can use various methods on this object to navigate, search, and modify the HTML content.\n",
    "For example, to print the title of the web page, you can use the title attribute of the html.head tag:\n",
    "title_tag = soup.title\n",
    "print(title_tag)\n",
    "This will output the title of the web page, such as \"Example Page - Example Website\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see this example too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>This is the first paragraph.</p>, <p class=\"highlighted\">This is the second paragraph.</p>, <p>This is the third paragraph.</p>]\n",
      "<p>This is the first paragraph.</p>\n",
      "<p class=\"highlighted\">This is the second paragraph.</p>\n",
      "<p>This is the third paragraph.</p>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Sample HTML content\n",
    "html_content = \"\"\"\n",
    "<html>\n",
    "<head><title>Sample Page</title></head>\n",
    "<body>\n",
    "<p>This is the first paragraph.</p>\n",
    "<p class=\"highlighted\">This is the second paragraph.</p>\n",
    "<p>This is the third paragraph.</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all the <p> tags in the HTML content\n",
    "paragraphs = soup.find_all('p')\n",
    "\n",
    "# Print the text content of each <p> tag\n",
    "print((paragraphs))\n",
    "for paragraph in paragraphs:\n",
    "    print(paragraph.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The IPython.display module \n",
    "\n",
    "provides a set of tools for displaying various types of content in IPython environments, such as Jupyter Notebooks. It supports displaying text, images, audio, and other rich media, making it a versatile tool for enhancing the interactive experience of working with Python code.\n",
    "Some key classes and functions provided by the IPython.display module include:\n",
    "IPython.display.Audio:\n",
    " This class creates an audio object that can be displayed in the IPython environment. It can be used with the display() function to play audio files or generate audio from text using libraries like gTTS.\n",
    "IPython.display.Image:\n",
    " This class is used to display images in the IPython environment. It can be used with the display() function to display images from local or remote sources.\n",
    "IPython.display.display_html:\n",
    " This function displays an HTML-formatted string in the IPython environment. It can be used to render HTML tables, charts, or other complex elements that are not supported by the default display() function\n",
    "IPython.display.clear_output:\n",
    " This function clears the output of the current cell in a Jupyter Notebook, allowing you to display new content without having to restart the kernel.\n",
    "To use the IPython.display module, you need to import the required classes or functions and then use them with the display() function or other supported functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The gTTS (Google Text-to-Speech) is \n",
    "a Python library and command-line tool that provides an interface to Google Translate's text-to-speech API. It allows users to convert text to speech and save it as an MP3 file. The gTTS library offers features such as customizable speech-specific sentence tokenizer, text pre-processors, and support for multiple languages. It is a convenient tool for generating speech from text and is widely used for various applications, including language processing and accessibility. The library can be installed using pip, and it provides both command-line and Python module interfaces for text-to-speech conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sumy library and:\n",
    "# from sumy.parsers.plaintext import PlaintextParser\n",
    "from perplexity AI:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sumy is a Python library and command-line utility used for automatic text summarization of documents and HTML pages\n",
    "# The PlaintextParser is a module in the Sumy library that\n",
    "is used for parsing plain text documents. It processes the input text and prepares it for summarization. The PlaintextParser is used to create a parser object that can be passed to the summarizer to generate a summary. The PlaintextParser is used to parse plain text documents, while the HtmlParser is used to parse HTML pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sumy.nlp.tokenizers and Tokenizer\n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tokenizer module is a part of the Sumy library in Python, which is used for automatic text summarization of documents and HTML pages. It is used to tokenize the input text into individual words or phrases, which can then be used for further processing. The Tokenizer module is used to create a tokenizer object that can be passed to the parser to tokenize the input text. The PlaintextParser and HtmlParser modules are used to parse plain text documents and HTML pages, respectively. The find_all method is a part of the BeautifulSoup library, which is used for finding all tags with a specified tag name or ID in an HTML or XML document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from sumy.summarizers.lsa import LsaSummarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LsaSummarizer class from the sumy.summarizers.lsa module in Python. \n",
    "The LsaSummarizer class is used for text summarization using the Latent Semantic Analysis (LSA) algorithm, which is a popular technique for automatically generating summaries of text documents.\n",
    "When using the LsaSummarizer, you need to provide a stemmer object as an argument to the constructor. The stemmer is used to remove common suffixes from words, such as \"ing\", \"ed\", and \"s\", to reduce the vocabulary size and improve the performance of the LSA algorithm.\n",
    "An example of it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explain those modules by bard AI:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "\n",
    "1. from sumy.parsers.plaintext import PlaintextParser\n",
    "Purpose: Parses plain text documents into a structured format that can be used by summarizers.\n",
    "Function:\n",
    "- Splits the text into paragraphs and sentences.\n",
    "- Identifies headings (lines in all uppercase).\n",
    "\n",
    "2. from sumy.nlp.tokenizers import Tokenizer\n",
    "Purpose: Splits text into individual words or tokens.\n",
    "Function:\n",
    "- Handles punctuation, spaces, special characters, etc.\n",
    "- Prepares text for further analysis.\n",
    "\n",
    "3. from sumy.summarizers.lsa import LsaSummarizer\n",
    "Purpose: Creates summaries using Latent Semantic Analysis (LSA).\n",
    "Function:\n",
    "- Analyzes text to identify key concepts and relationships.\n",
    "- Selects sentences that best represent the overall meaning.\n",
    "\n",
    "Here is simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample text to be summarized.\n",
      "It contains several sentences and paragraphs.\n",
      "It discusses a different topic.\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "# Sample text to summarize\n",
    "text = \"This is a sample text to be summarized. It contains several sentences and paragraphs.\\n\\nThis is a new paragraph. It discusses a different topic.\"\n",
    "\n",
    "# Create the parser and tokenizer\n",
    "parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "\n",
    "# Create the summarizer\n",
    "summarizer = LsaSummarizer()\n",
    "\n",
    "# Generate a summary with 3 sentences\n",
    "summary = summarizer(parser.document, 3)\n",
    "\n",
    "# Print the summary\n",
    "for sentence in summary:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above code, Explanation:\n",
    "\n",
    "Imports the necessary modules.\n",
    "Creates sample text to summarize.\n",
    "Creates a PlaintextParser to parse the text and a Tokenizer to split it into words.\n",
    "Creates an LsaSummarizer to generate the summary.\n",
    "Generates a summary with 3 sentences.\n",
    "Prints the sentences in the summary.\n",
    "Key Points:\n",
    "\n",
    "These modules are part of the sumy library for automatic text summarization in Python.\n",
    "They work together to:\n",
    "Parse plain text documents.\n",
    "Prepare text for analysis.\n",
    "Generate summaries using LSA.\n",
    "You can adjust the number of sentences in the summary as needed.\n",
    "\n",
    "# Source: https://medium.com/newolf-society/samuraiser-the-youtube-transcript-summarizing-extension-89434153d2bc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base64\n",
    "\n",
    "In Python, the base64 module provides functions for encoding binary data to printable ASCII characters and decoding such encodings back to binary data. It offers an easy way to encrypt and decrypt binary data using the Base64 encoding technique. The base64 module includes functions such as b64encode() for encoding data and b64decode() for decoding data. Base64 encoding is a common method for converting binary data into a string of printable ASCII characters, enabling the secure transmission of data. When using the b64encode() function, it's important to provide a bytes-like object as input, not a regular string, to avoid potential TypeErrors. The module also supports URL-safe encoding and decoding. Overall, the base64 module is a built-in and effective tool for encoding and decoding binary data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, review;\n",
    "Now first, see the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from gtts import gTTS\n",
    "import base64\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "# Your existing functions\n",
    "def fetch_data_from_url(url):\n",
    "    #sends an HTTP GET request to URL\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    article_text = ' '.join([p.text for p in soup.find_all('p')])\n",
    "    return article_text\n",
    "\n",
    "def summarize_text(text, sentence_count=5):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, sentence_count)\n",
    "    return [str(sentence) for sentence in summary]\n",
    "\n",
    "def text_to_speech(text):\n",
    "    language = 'en'\n",
    "    tts = gTTS(text=text, lang=language, slow=False)\n",
    "    tts.save(\"summary.mp3\")\n",
    "    return ipd.Audio(\"summary.mp3\", autoplay=True)\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Input(id='url-input', type='text', placeholder='Enter URL'),\n",
    "    html.Button('Fetch and Summarize', id='fetch-button'),\n",
    "    html.Audio(id='audio-output', controls=True, style={'display': 'none'}),\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('audio-output', 'src'),\n",
    "    Input('fetch-button', 'n_clicks'),\n",
    "    [State('url-input', 'value')]\n",
    ")\n",
    "def fetch_and_summarize(n_clicks, url):\n",
    "    if n_clicks is None:\n",
    "        return\n",
    "\n",
    "    article_text = fetch_data_from_url(url)\n",
    "    summary_sentences = summarize_text(article_text)\n",
    "    summary_text = \" \".join(summary_sentences)\n",
    "\n",
    "    tts = gTTS(text=summary_text, lang='en', slow=False)\n",
    "    tts.save(\"summary.mp3\")\n",
    "\n",
    "    with open(\"summary.mp3\", \"rb\") as audio_file:\n",
    "        encoded_audio = base64.b64encode(audio_file.read()).decode()\n",
    "\n",
    "    return \"data:audio/mpeg;base64,{}\".format(encoded_audio)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a breakdown of your code, line by line, in simple and complete terms:\n",
    "\n",
    "Import Libraries:\n",
    "\n",
    "Imports tools for building the app and its functionalities:\n",
    "dash: Creates the web app framework.\n",
    "dash_core_components and dash_html_components: Provide components like text boxes, buttons, audio players.\n",
    "requests: Fetches data from URLs.\n",
    "BeautifulSoup: Parses HTML content.\n",
    "sumy: Summarizes text.\n",
    "gtts: Converts text to speech.\n",
    "base64: Encodes audio data for playback in the browser.\n",
    "Define Functions:\n",
    "\n",
    "fetch_data_from_url(url):\n",
    "\n",
    "Retrieves text content from a given URL:\n",
    "Sends an HTTP GET request to the URL using requests.get(url).\n",
    "Parses the HTML content with BeautifulSoup.\n",
    "Extracts text from paragraphs using soup.find_all('p').\n",
    "Joins the extracted text into a single string and returns it.\n",
    "summarize_text(text, sentence_count=5):\n",
    "\n",
    "Summarizes a text string into a specified number of sentences:\n",
    "Creates a parser for plain text using PlaintextParser.\n",
    "Creates an LSA summarizer (a text summarization algorithm).\n",
    "Generates a summary with summarizer(parser.document, sentence_count).\n",
    "Returns the summary as a list of sentences.\n",
    "text_to_speech(text):\n",
    "\n",
    "Converts text to an MP3 audio file and returns a base64-encoded audio source:\n",
    "Creates a text-to-speech object using gTTS(text=text, lang='en').\n",
    "Saves the audio as \"summary.mp3\".\n",
    "Opens the MP3 file, reads its content, and base64 encodes it.\n",
    "Returns the base64-encoded audio source for playback in the browser.\n",
    "Create Dash App:\n",
    "\n",
    "app = dash.Dash(__name__): Initializes a Dash app instance.\n",
    "App Layout:\n",
    "\n",
    "app.layout: Defines the app's visual structure using HTML components:\n",
    "dcc.Input(id='url-input'): A text box for entering a URL.\n",
    "html.Button('Fetch and Summarize'): A button to trigger the summarization process.\n",
    "html.Audio(id='audio-output'): An audio player to play the generated summary.\n",
    "Callback:\n",
    "\n",
    "@app.callback(...): Links user interactions to actions in the app:\n",
    "Monitors changes in the url-input and fetch-button.\n",
    "Calls the fetch_and_summarize function when the button is clicked.\n",
    "fetch_and_summarize Function:\n",
    "\n",
    "Retrieves URL content, summarizes it, and generates audio:\n",
    "Fetches article text using fetch_data_from_url.\n",
    "Creates a summary using summarize_text.\n",
    "Converts the summary to audio using text_to_speech.\n",
    "Returns the audio source for playback in the audio player.\n",
    "Run the App:\n",
    "\n",
    "app.run_server(debug=True): Starts the Dash app server in debug mode."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
